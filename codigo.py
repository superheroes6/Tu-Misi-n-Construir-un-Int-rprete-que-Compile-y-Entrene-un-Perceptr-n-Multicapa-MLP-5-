# Importamos todas las librer√≠as necesarias para trabajar con arrays, deep learning, visualizaci√≥n y m√©tricas
import numpy as np
import tensorflow as tf 
from keras.models import Sequential
from keras.layers import Dense, Input
from keras.datasets import mnist
from sklearn.metrics import confusion_matrix, classification_report
import matplotlib.pyplot as plt
from tensorflow.keras.utils import to_categorical

# Cargamos el dataset MNIST, que contiene im√°genes de d√≠gitos escritos a mano.
# trainX y trainY son las im√°genes y etiquetas de entrenamiento, testX y testY las de prueba
(trainX, trainY), (testX, testY) = mnist.load_data()

# Mostramos la forma de los arrays para entender c√≥mo est√°n organizados los datos
print("TrainX:", trainX.shape)  # N√∫mero de im√°genes de entrenamiento, alto y ancho
print("TrainY:", trainY.shape)  # N√∫mero de etiquetas de entrenamiento
print("TestX:", testX.shape)    # N√∫mero de im√°genes de prueba
print("TestY:", testY.shape)    # N√∫mero de etiquetas de prueba

# Creamos una funci√≥n para visualizar un d√≠gito cualquiera del dataset
def display_digit(index):
    image = trainX[index].reshape([28, 28])  # Damos forma a la imagen (28x28 p√≠xeles)
    label = trainY[index]                     # Obtenemos la etiqueta real del d√≠gito
    plt.title(f"Training data, index: {index}, Label: {label}")
    plt.imshow(image, cmap='gray_r')         # Mostramos la imagen en escala de grises
    plt.show()

# Por ejemplo, mostramos el d√≠gito en la posici√≥n 2
display_digit(2)

# Normalizamos los valores de p√≠xeles a un rango 0-1 dividiendo entre 255
# Esto ayuda al entrenamiento de la red neuronal
trainX_norm = trainX / 255.0
testX_norm = testX / 255.0

# Convertimos las etiquetas a formato one-hot para clasificaci√≥n multi-clase
# Por ejemplo, el d√≠gito 3 pasa a [0,0,0,1,0,0,0,0,0,0]
trainY_cate = to_categorical(trainY)
testY_cate = to_categorical(testY)

# Calculamos la dimensi√≥n de entrada de la red neuronal (28x28 = 784 p√≠xeles)
dimension_input = trainX.shape[1] * trainX.shape[2]

# Creamos una funci√≥n que define nuestro modelo MLP (Perceptr√≥n Multicapa)
def build_model():
    model = Sequential()  
    # La primera capa recibe vectores de 784 valores (los p√≠xeles aplanados)
    model.add(Input(shape=(dimension_input,)))
    # Capa oculta con 784 neuronas y activaci√≥n ReLU
    model.add(Dense(dimension_input, activation='relu'))
    # Segunda capa oculta con 64 neuronas y activaci√≥n ReLU
    model.add(Dense(64, activation='relu'))
    # Capa de salida con 10 neuronas (una por d√≠gito) y activaci√≥n softmax
    model.add(Dense(10, activation='softmax'))

    # Compilamos el modelo indicando:
    # - Optimizer: 'adam' ajusta los pesos autom√°ticamente
    # - Loss: 'categorical_crossentropy' porque es clasificaci√≥n multi-clase
    # - Metrics: 'accuracy' para evaluar cu√°ntos aciertos tiene
    model.compile(
        optimizer='adam',
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )
    return model

# Creamos el modelo llamando a la funci√≥n
model_tofit = build_model()

# Mostramos un resumen del modelo, con el n√∫mero de par√°metros de cada capa
model_tofit.summary()

# Aplanamos las im√°genes para que cada fila sea un vector de 784 valores
trainX_norm = trainX_norm.reshape(trainX_norm.shape[0], dimension_input)
testX_norm = testX_norm.reshape(testX_norm.shape[0], dimension_input)

# Entrenamos el modelo con los datos normalizados y las etiquetas one-hot
# Validamos con el set de prueba, usamos 5 √©pocas y batch size de 128
model_tofit.fit(
    trainX_norm,
    trainY_cate,
    validation_data=(testX_norm, testY_cate),
    epochs=5,
    batch_size=128,
    verbose=2
)

# Realizamos predicciones sobre el set de prueba
# argmax obtiene la clase con mayor probabilidad para cada imagen
predictions = np.array(model_tofit.predict(testX_norm)).argmax(axis=1)

# Convertimos las etiquetas reales a valores num√©ricos (de one-hot a d√≠gito)
actual = testY_cate.argmax(axis=1)

# Calculamos la precisi√≥n del modelo como el porcentaje de aciertos
test_accuracy = np.mean(predictions == actual)
print("\n‚úÖ Test accuracy:", test_accuracy)

# Generamos la matriz de confusi√≥n, que muestra cu√°ntos d√≠gitos fueron clasificados correctamente e incorrectamente
cm = confusion_matrix(y_true=actual, y_pred=predictions)
print("\nüìä Matriz de confusi√≥n:")
print(cm)

# Generamos un informe de clasificaci√≥n detallado, con precisi√≥n, recall y f1-score para cada d√≠gito
print("\nüìÑ Informe de clasificaci√≥n:")
print(classification_report(actual, predictions))
